---
layout: post
title: Message Passing for Complex Question Answering over Knowledge Graphs
categories: DailyPaper
description: Daily Paper 002
keywords: paper
---


> This paper proposes a novel approach for **complex KGQA** that uses unsupervised message passing, which propagates confidence scores obtained by parsing an input question and matching terms in the knowledge graph to a set of possible answers. First,  identifing entity, relationship, and class names mentioned in a natural language question, and map these to their counterparts in the graph. Then, the confidence scores of these mappings propagate through the graph structure to locate the answer entities. Finally, these are aggregated depending on the identified question type.  

​		


#### Author(s) & Source

**Svitlana Vakulenko**：阿姆斯特丹大学语言理解和信息搜索研究所（ILPS）数据科学博士后，研究方向为自然语言处理、对话系统、问答、对话搜索；

**Javier David Fernandez Garcia**；

**Axel Polleres**：维也纳经济与商业大学信息服务研究所所长，研究方向为知识管理、逻辑程序设计、语义网、知识图谱；

**Maarten de Rijke**：阿姆斯特丹大学，研究方向为信息抽取、人工智能；

**Michael Cochez**.

​		



本文发表于**CIKM 2019**，https://arxiv.org/pdf/1908.06917。

**CIKM** 全称为International Conference on Information and Knowledge Management，是国际计算机学会（ACM）主办的数据库、知识管理、信息检索领域的重要学术会议，1992年首次举办。
第28届CIKM2019年11月3日至7日在中国北京举行，本次会议收到 1676 篇提交论文（其中包括 1031 篇长论文和 471 篇短论文），经过同行评审，共有 202 篇长论文、107 篇短论文和 37 篇应用研究论文被接收，总接受率约为 21%。

**CIKM 2020**举办地点：Galway, Ireland；摘要截稿：2020-04-24；全文截稿：2020-05-01；开会时间：2020-10-19-23；CCF分类：B类。

​	



#### Content & Comment

许多KGQA系统只能回答简单问题（依赖一个三元组、单跳），为此提出 QAmp 模型，能够回答复杂问题（融合多个三元组、多跳），在 LC-QuAD  数据集取得SOTA结果。

 - **INTRODUCTION**，介绍逻辑为：海量数据需要强大的信息处理能力，其中问答是一种有效形式；当前多数问答系统依赖知识图谱；KGQA 系统分别解决简单问题或复杂问题；对于复杂问题问答极具挑战，本文提出 QAmp；最后简单介绍了 QAmp 的特点及结果。

 - **RELATED WORK**，包括面向简单问题或复杂问题的KGQA系统对比、一般的KGQA系统pipeline、相近工作及baseline、图神经网络。

 - **QAmp细节介绍及实现方法**，QAmp框架主要分两部分：问句分析和答案推理，其中问句分析识别问句中的实体、关系、类型实体（可参见下图左）以及问句类型（LC-QuAD数据集中问题类型分三种），然后将识别结果映射到知识图谱；答案推理即为逐跳搜索过程，每一步都进行message passing更新状态，循环直到最后一跳，结合问句类型确定正确答案。下面是详细介绍。

   <figure class="half">
   	<img src="https://s2.ax1x.com/2020/02/08/1WGj8H.png"  width= "50%"><img src="https://s2.ax1x.com/2020/02/08/1WsjTH.png"  width="50%">
   </figure>

   问句分析分两步：

   1. 解析。如上图右所示，作者将问题定义为$q=<t_q, Seq_q>$，相应的，解析过程为根据问题识别问句类型$t_q$以及n跳序列$Seq_q=(<E^i,P^i,C^i>)^h_{i=1}$。具体实现中，将问句类型视为一个多分类问题（本文数据集为三分类），以监督学习的方式（Bi-LSTM）进行训练；将n跳序列视为序列标注问题，同样用标注数据进行监督学习（CRF+Bi-LSTM）。
   2. 匹配。根据n跳序列中的$E, P, C$匹配知识图谱中的实体与关系，得到相应的URI以及置信度（基于索引的方法和基于嵌入的方法），如下图。

   <img src="https://s2.ax1x.com/2020/02/08/1W2ysP.png" style="zoom:50%;" />
   
   答案推理也分两步：

   1. 子图抽取。对于每一跳$<E, P, C>$，从知识图谱中抽取至少包含$<E,P,C>$中一个实体和一个关系的三元组，所有满足条件的三元组组成该跳子图。
2. 信息传递。在子图中执行信息传递以更新候选答案实体（子图中未含于$E,C$的实体）的置信度得分，即根据相邻实体URI和关系URI的置信度计算答案实体置信度。该算法是本文的核心，更新过程包括三步：关系更新、实体更新、置信度分数汇总。算法公式抽象难懂，可结合作者论文中的例子学习。
   
   <figure class="half">
   	<img src="https://s2.ax1x.com/2020/02/10/14tyTI.png"  width= "50%"><img src="https://s2.ax1x.com/2020/02/10/14tgtP.png"  width="50%">
   </figure>
   
   <img src="https://s2.ax1x.com/2020/02/10/146O9H.png" style="zoom:50%;" />
   
   每一跳以此执行上述两步，得到该跳的答案实体，将推理结果连同其置信度传递到下一跳，重复答案推理步骤，直到最后一跳，将其推理结果作为答案。

<img src="https://s2.ax1x.com/2020/02/10/146O9H.png" style="zoom:50%;" />

 - **实验分析和结论**。



​	



------

⭐⭐⭐⭐	这篇文章的一作是去年（2019年）博士毕业的小姐姐，在她的博士论文 Knowledge-based Conversational Search 介绍了这篇文章，另外她的博士论文原文也值得一读，有兴趣的可以 Google scholar 搜索阅读。我觉得文章值得借鉴的地方有：对问句模式的定义$q=<t_q, Seq_q>$；Message passing中的矩阵代数运算；不考虑知识图谱中关系的方向等。



以上仅代表本人见解，如有纰漏，敬请指正！